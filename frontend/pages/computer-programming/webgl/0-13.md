## <div align='center'>Framebuffers & Post Processing</div>

<br>In WebGL, framebuffers are like collections of attachments of different types of textures. The attachments can be color, depth, or stencil attachments. Framebuffers are especially useful as they allow you to render to a texture. You can attach a texture to a framebuffer, bind the framebuffer, draw geometry, and it'll end up in the framebuffer's attached texture instead of the canvas!<br><br>Rendering to a texture will allow you to perform post processing on the rendered image. You can apply effects like blurring, bloom, and color grading to the final image.<br><br>First, create a new _"WebGLProgramObject"_ that performs the post processing. In this example, the post processing shader will invert the colors of the rendered image.
```js
let pp_program=createProgram(`#version 300 es
    
	precision mediump float;
    
	in vec2 vertPos;
    
	out vec2 pixUV;
    
	void main(){
   	 
    	pixUV=vertPos*0.5+0.5;
    	gl_Position=vec4(vertPos,0,1);
	}

`,`#version 300 es
    
	precision mediump float;
    
	in vec2 pixUV;
    
	uniform sampler2D tex;
    
	out vec4 fragColor;
    
	void main(){
   	 
    	fragColor=vec4(1.0-texture(tex,pixUV).rgb,1);
	}
`)
```
After creating the original mesh, we create a 2D mesh that covers the screen. The screen mesh can be created using 2 triangles forming a rectangle that covers the screen, or from 1 large triangle. Here, we also get the attribute location while we're at it:
```js
let pp_vertPosLocation=gl.getAttribLocation(program,'vertPos')
gl.enableVertexAttribArray(pp_vertPosLocation)

let pp_buffer=gl.createBuffer()

gl.bindBuffer(gl.ARRAY_BUFFER,pp_buffer)

//vertices are a large triangle covering the screen
//the format of the buffer is x1,y1,x2,y2,x3,y3
gl.bufferData(gl.ARRAY_BUFFER,new Float32Array([-1,-1,3,-1,-1,3]),gl.STATIC_DRAW)
```
We now create the texture and framebuffer. We also have to attach a depth renderbuffer to the framebuffer in order for the program to perform depth testing when rendering to a texture.
```js
//create the texture to be rendered to
let texture=gl.createTexture()
gl.bindTexture(gl.TEXTURE_2D,texture)

//data is "null" as it's not needed to be set here
gl.texImage2D(gl.TEXTURE_2D,0,gl.RGBA,canvas.width,canvas.height,0,gl.RGBA,gl.UNSIGNED_BYTE,null)

gl.texParameteri(gl.TEXTURE_2D,gl.TEXTURE_MIN_FILTER,gl.LINEAR)


//create the framebuffer
let framebuffer=gl.createFramebuffer()

//bind the framebuffer
gl.bindFramebuffer(gl.FRAMEBUFFER,framebuffer)

//attach the texture to the framebuffer
gl.framebufferTexture2D(gl.FRAMEBUFFER,gl.COLOR_ATTACHMENT0,gl.TEXTURE_2D,texture,0)

//create a depth renderbuffer and attach it to the framebuffer
let depthBuffer=gl.createRenderbuffer()
gl.bindRenderbuffer(gl.RENDERBUFFER,depthBuffer)
gl.renderbufferStorage(gl.RENDERBUFFER,gl.DEPTH_COMPONENT16,canvas.width,canvas.height)
gl.framebufferRenderbuffer(gl.FRAMEBUFFER,gl.DEPTH_ATTACHMENT,gl.RENDERBUFFER,depthBuffer)
```
Then, we update the rendering process...
```js
//stuff rendered after a bound framebuffer with render to the framebuffer's attached texture
gl.bindFramebuffer(gl.FRAMEBUFFER,framebuffer)

//use the normal program
gl.useProgram(program)


//original cube mesh rendering goes here...


//unbinds the framebuffer, meaning stuff after draws to the real canvas
gl.bindFramebuffer(gl.FRAMEBUFFER,null)

//"texture" now contains the rendered cube!
gl.bindTexture(gl.TEXTURE_2D,texture)

//use the post processing program
gl.useProgram(pp_program)

//draw the big triangle that covers the screen
gl.bindBuffer(gl.ARRAY_BUFFER,pp_buffer)
gl.vertexAttribPointer(pp_vertPosLocation,2,gl.FLOAT,gl.FALSE,8,0)
gl.drawArrays(gl.TRIANGLES,0,3)
```
You should see the same cube, but the final rendered image's color is inverted!